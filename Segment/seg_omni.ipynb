{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import clip\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from segment_anything.utils.transforms import ResizeLongestSide \n",
    "\n",
    "from PIL import Image  \n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from sam_caf import hyper_params_tuning, get_crops, retrieve_relevant_crop, retrieve_relevant_crop_biomed, get_sam_prompts, sam_predicton, retrieve_relevant_crop_biomed_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "class DictToObject:\n",
    "    def __init__(self, dict_obj):\n",
    "        for key, value in dict_obj.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "config_dict = {\n",
    "    \"model_name\" : \"SAM\",\n",
    "    \"model_type\" : \"vit_h\",\n",
    "    \"source\":    \"False\", \n",
    "    \"refine\" : \"False\",\n",
    "    \"pre_trained\": \"True\", \n",
    "    \"sam_ckpt\":  \"/data/aofei/LLM/SAM/sam_vit_h_4b8939.pth\", \n",
    "    \"clip_prompts\": \"./clip_prompts/abd_seg.json\"\n",
    "}\n",
    "\n",
    "config = DictToObject(config_dict)\n",
    "\n",
    "prompt_mode, mode = \"crops\", \"sam_clip\"\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"]=\"/data/aofei/huggingface_cache/transformers\"\n",
    "os.environ[\"HF_HOME\"]=\"/data/aofei/huggingface_cache/transformers\"\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer # works on open-clip-torch>=2.23.0, timm>=0.9.8\n",
    "\n",
    "biomed_clip_model, biomed_preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224', device=\"cuda\")\n",
    "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-L/14\", device=\"cuda\")\n",
    "sam_checkpoint = config.sam_ckpt\n",
    "\n",
    "sam = sam_model_registry[config.model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(\"cuda\")\n",
    "resize_transform = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "dice_scores = []\n",
    "mask_generator, area = hyper_params_tuning(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam_generation(image_path):\n",
    "    image = preprocess_image(image_path=image_path)\n",
    "    with torch.no_grad():\n",
    "        # if mode == \"sam_clip\":\n",
    "        masks = mask_generator.generate(image)\n",
    "        masks = [mask for mask in masks if mask[\"area\"] < area] # area filtering based on area value from hyper-params tuning\n",
    "        img_crops = get_crops(image, masks, prompt_mode)\n",
    "        \n",
    "    return masks, img_crops\n",
    "\n",
    "def filter_sam_results(masks, img_crops):\n",
    "    new_masks, new_img_crops = [], []\n",
    "    for i in range(len(masks)):\n",
    "        mask = masks[i]\n",
    "        if mask['bbox'][0] == 0 or mask['bbox'][1] == 0:\n",
    "            continue\n",
    "        if mask['bbox'][2] <= 12 or mask['bbox'][3] <= 12:\n",
    "            continue\n",
    "        y_max, x_max = mask['bbox'][1] + mask['bbox'][3], mask['bbox'][0] + mask['bbox'][2]\n",
    "        if y_max > 253 or x_max > 253:\n",
    "            continue\n",
    "        new_masks.append(mask)\n",
    "        new_img_crops.append(img_crops[i])\n",
    "    return new_masks, new_img_crops\n",
    "\n",
    "def get_topk_similar(k, crop_scores):\n",
    "    sorted_scores = sorted([(i, m) for (i,m) in enumerate(crop_scores)], key=lambda x: x[1], reverse=True)\n",
    "    return sorted_scores[:k]\n",
    "\n",
    "def get_compelete_contour(masks):\n",
    "    width_list = []\n",
    "    # need to consider the chest xray\n",
    "    for i in masks:\n",
    "        width, height = i['bbox'][2], i['bbox'][3]\n",
    "        width_list.append(width)\n",
    "    sorted_width = sorted([(i, m) for (i,m) in  enumerate(width_list)], key=lambda x: x[1], reverse=True)\n",
    "    return sorted_width[0][1]\n",
    "\n",
    "def judge_inner_boxes(bboxes):\n",
    "    for bbox in bboxes:\n",
    "        bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_image_dict = dict()\n",
    "masks_all_image_dict = dict()\n",
    "crops_image_dict = dict()\n",
    "def generate_segments(query, image_path):\n",
    "    if masks_image_dict.__contains__(image_path):\n",
    "        masks = masks_image_dict[image_path]\n",
    "        img_crops = crops_image_dict[image_path]\n",
    "    else:\n",
    "        masks, img_crops = sam_generation(image_path=image_path)\n",
    "        masks, img_crops = filter_sam_results(masks, img_crops)\n",
    "        masks_image_dict[image_path] = masks\n",
    "        crops_image_dict[image_path] = img_crops\n",
    "    img_crops_filtered = img_crops\n",
    "    prompts = {\"query\": [query]}\n",
    "    max_indices, scores = retrieve_relevant_crop_biomed_topk(img_crops, prompts, biomed_clip_model, biomed_preprocess, config, tokenizer=tokenizer, topk=4)\n",
    "    # topk_indices = get_topk_similar(3, scores[\"query\"])\n",
    "    # define a set of rules, firstly return top3\n",
    "    # if there is no explicit organs to be used as query, then just use the whole segmentation\n",
    "    # if the smaller boxes are in the bigger box, then use all of them but assign higher weights on smaller inner boxes\n",
    "    bboxes = []\n",
    "    segs = []\n",
    "    # print(max_indices)\n",
    "    if max_indices is not None:\n",
    "        for i in max_indices[\"query\"]:\n",
    "            bboxes.append(masks[i][\"bbox\"])\n",
    "            segs.append(masks[i][\"segmentation\"])\n",
    "        return bboxes, segs, max_indices[\"query\"]\n",
    "    else:\n",
    "        return bboxes, segs, []\n",
    "\n",
    "\n",
    "def generate_all_segments(image_path):\n",
    "    if masks_all_image_dict.__contains__(image_path):\n",
    "        masks = masks_all_image_dict[image_path]\n",
    "    else:\n",
    "        masks, img_crops = sam_generation(image_path=image_path)\n",
    "        masks, img_crops = filter_sam_results(masks, img_crops)\n",
    "        masks_all_image_dict[image_path] = masks\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"/data/aofei/hallucination/CARES/OmniMedVQA/training.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "len(data)\n",
    "all_train_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'Images/Adam Challenge/AMD/A0017.jpg',\n",
       " 'id': 'Adam Challenge_0000_train0',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat imaging technique is employed to acquire this fundus image? options: X-ray imaging, Fundus photography, Ultrasound imaging, Magnetic resonance imaging (MRI)'},\n",
       "  {'from': 'gpt', 'value': 'Fundus photography'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_en = all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6155"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "train_data_seg = copy.deepcopy(all_train_data_en)\n",
    "len(train_data_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5731"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i['image'] for i in train_data_seg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(set([i['img_name'] for i in train_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 177/6155 [06:40<3:22:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 291/6155 [11:21<3:02:56,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 312/6155 [12:10<4:15:39,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 313/6155 [12:13<4:19:01,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 347/6155 [13:15<2:41:33,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 414/6155 [15:50<4:18:48,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 442/6155 [17:07<4:22:47,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 472/6155 [18:29<4:21:11,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 482/6155 [18:56<4:20:30,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n",
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 487/6155 [19:10<4:17:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 529/6155 [21:03<4:17:30,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 533/6155 [21:14<4:15:11,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 712/6155 [28:12<3:07:57,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 718/6155 [28:28<4:00:01,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 750/6155 [29:42<2:49:25,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 776/6155 [30:34<3:24:38,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 791/6155 [31:07<3:24:37,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 981/6155 [39:02<3:42:35,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1244/6155 [49:40<3:47:17,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1263/6155 [50:33<3:45:49,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1302/6155 [52:21<3:42:49,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1527/6155 [1:02:43<3:30:54,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n",
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1604/6155 [1:06:16<3:28:01,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1625/6155 [1:07:14<3:30:52,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1692/6155 [1:10:21<3:29:17,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1838/6155 [1:17:11<3:21:26,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1887/6155 [1:19:28<3:20:33,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1965/6155 [1:23:04<3:15:48,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 2133/6155 [1:30:49<3:08:11,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n",
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2258/6155 [1:36:36<3:00:43,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2294/6155 [1:38:16<2:59:01,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 2377/6155 [1:42:07<2:54:29,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2474/6155 [1:46:37<2:47:16,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2592/6155 [1:52:03<2:43:41,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2694/6155 [1:56:47<2:36:35,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 2778/6155 [2:00:40<2:40:32,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2973/6155 [2:09:43<2:27:06,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 3037/6155 [2:12:41<2:24:59,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 3047/6155 [2:13:09<2:24:01,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3108/6155 [2:15:59<2:23:16,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 3174/6155 [2:19:02<2:19:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n",
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 3679/6155 [2:42:20<1:53:45,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3708/6155 [2:43:41<1:54:42,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3758/6155 [2:46:00<1:50:05,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3763/6155 [2:46:14<1:51:30,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3840/6155 [2:49:48<1:46:32,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 3970/6155 [2:55:46<1:41:30,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4127/6155 [3:02:55<1:34:23,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 4236/6155 [3:07:57<1:27:51,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 4353/6155 [3:13:19<1:23:31,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 4458/6155 [3:18:10<1:18:46,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4570/6155 [3:23:22<1:13:56,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4584/6155 [3:24:01<1:13:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 6053/6155 [4:20:13<04:33,  2.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 6066/6155 [4:20:45<03:56,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n",
      "Skipping zero-sized bounding box.\n",
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6155/6155 [4:21:59<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(train_rad_data)):\n",
    "#failure case: 432-3 + 100\n",
    "# from tqdm import tqdm\n",
    "for i in tqdm(range(len(train_data_seg))):\n",
    "# for i in tqdm(range(20)):\n",
    "    data = train_data_seg[i]\n",
    "    image_path = os.path.join('/data/aofei/hallucination/OmniMedVQA/VQA/raw/OmniMedVQA', data[\"image\"])\n",
    "    question = data[\"conversations\"][0][\"value\"].replace(\"<image>\\n\", \"\")\n",
    "    # question = question.split(\"The candidate Options are:\")[0]\n",
    "    # print(question)\n",
    "    query = question\n",
    "\n",
    "    bbox, segs, max_indices = [], [], []\n",
    "    try:\n",
    "        bbox, segs, max_indices = generate_segments(query, image_path)\n",
    "    except:\n",
    "        continue\n",
    "    # print(bbox)\n",
    "    data['bbox'] = bbox\n",
    "    data['mask'] = segs\n",
    "    data[\"bbox_indices\"] = max_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(train_data_seg[0]['mask'][0])\n",
    "np.sum(train_data_seg[0]['mask'][1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in train_data_seg:\n",
    "    if not i.__contains__(\"mask\"):\n",
    "        s+= 1\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'Images/Adam Challenge/Non-AMD/N0051.jpg',\n",
       " 'id': 'Adam Challenge_0003_train3',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat method is employed to obtain this fundus image? options: Ultrasound imaging, Magnetic resonance imaging (MRI), Spirometry, Fundus photography'},\n",
       "  {'from': 'gpt', 'value': 'Fundus photography'}],\n",
       " 'bbox': [[95, 150, 27, 26],\n",
       "  [25, 87, 35, 40],\n",
       "  [41, 94, 19, 31],\n",
       "  [196, 180, 47, 45]],\n",
       " 'mask': [array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]),\n",
       "  array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]),\n",
       "  array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]),\n",
       "  array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]])],\n",
       " 'bbox_indices': [2, 1, 0, 3]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_seg[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'Images/MIAS/mdb188.png',\n",
       " 'id': 'MIAS_0134_train6149',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat type of abnormality is depicted in this image? options: Spiculated masses, Metastatic tumors, Scar tissue formations, Cystic lesions'},\n",
       "  {'from': 'gpt', 'value': 'Spiculated masses'}],\n",
       " 'bboxes': [[65, 39, 102, 183]],\n",
       " 'masks': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_train_data = []\n",
    "segments_dict = dict()\n",
    "for i in train_data_seg:\n",
    "    template = dict()\n",
    "    \n",
    "    # template['answer_type'] = i['answer_type']\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = i['id']\n",
    "    template['conversations'] = []\n",
    "    template['bboxes'] = []\n",
    "    template['masks'] = []\n",
    "    segments_dict[str(i['id'])] = []\n",
    "    if i.__contains__(\"bbox\"):\n",
    "        template['bboxes'] = i[\"bbox\"]\n",
    "    if i.__contains__(\"mask\"):\n",
    "        segments_dict[str(i['id'])] = i[\"mask\"]\n",
    "\n",
    "    # if i.__contains__(\"mask\"):\n",
    "    #     json_ready_segments = [\n",
    "    #         arr.astype(int).tolist() for arr in i[\"mask\"]\n",
    "    #     ]\n",
    "    #     template['masks'] = json_ready_segments\n",
    "    # template['text'] = i['question']\n",
    "\n",
    "    # new_qa = {\"from\": \"human\", \"value\": i['question']}\n",
    "    # new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer'])}\n",
    "    template['conversations'] = i['conversations']\n",
    "    new_train_data.append(template)\n",
    "\n",
    "new_train_data[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data_top4 = []\n",
    "for i in new_train_data:\n",
    "    j = i.copy()\n",
    "    j[\"bboxes\"] = j[\"bboxes\"][:4]\n",
    "    new_train_data_top4.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'Images/DeepDRiD/regular-fundus-test/463/463_r1.jpg',\n",
       " 'id': 'DeepDRiD_0054_train100',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat type of imaging technique was used to capture this image? options: fundus photography., Electrocardiogram (ECG)., Endoscopy., MRI.'},\n",
       "  {'from': 'gpt', 'value': 'fundus photography.'}],\n",
       " 'bboxes': [[167, 43, 46, 42]],\n",
       " 'masks': []}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data_top4[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segments_dict['0']\n",
    "ed = 0\n",
    "for i in segments_dict:\n",
    "    if len(segments_dict[i]) == 0:\n",
    "        ed += 1\n",
    "ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the masks to npz file\n",
    "\n",
    "np.savez_compressed(\"/data/aofei/hallucination/CARES/OmniMedVQA/training_segments_top4.npz\", **segments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6155"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/aofei/hallucination/CARES/OmniMedVQA/training_masks_top4.json', 'w') as json_file:\n",
    "    json.dump(new_train_data_top4, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
