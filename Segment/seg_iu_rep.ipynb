{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import clip\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from segment_anything.utils.transforms import ResizeLongestSide \n",
    "\n",
    "from PIL import Image  \n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from sam_caf import hyper_params_tuning, get_crops, retrieve_relevant_crop, retrieve_relevant_crop_biomed, get_sam_prompts, sam_predicton, retrieve_relevant_crop_biomed_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "class DictToObject:\n",
    "    def __init__(self, dict_obj):\n",
    "        for key, value in dict_obj.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "config_dict = {\n",
    "    \"model_name\" : \"SAM\",\n",
    "    \"model_type\" : \"vit_h\",\n",
    "    \"source\":    \"False\", \n",
    "    \"refine\" : \"False\",\n",
    "    \"pre_trained\": \"True\", \n",
    "    \"sam_ckpt\":  \"/data/aofei/LLM/SAM/sam_vit_h_4b8939.pth\", \n",
    "    \"clip_prompts\": \"./clip_prompts/abd_seg.json\"\n",
    "}\n",
    "\n",
    "config = DictToObject(config_dict)\n",
    "\n",
    "prompt_mode, mode = \"crops\", \"sam_clip\"\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/data/aofei/conda/env/medh/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"]=\"/data/aofei/huggingface_cache/transformers\"\n",
    "os.environ[\"HF_HOME\"]=\"/data/aofei/huggingface_cache/transformers\"\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer # works on open-clip-torch>=2.23.0, timm>=0.9.8\n",
    "\n",
    "biomed_clip_model, biomed_preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224', device=\"cuda\")\n",
    "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-L/14\", device=\"cuda\")\n",
    "sam_checkpoint = config.sam_ckpt\n",
    "\n",
    "sam = sam_model_registry[config.model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(\"cuda\")\n",
    "resize_transform = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "dice_scores = []\n",
    "mask_generator, area = hyper_params_tuning(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sam_generation(image_path):\n",
    "    image = preprocess_image(image_path=image_path)\n",
    "    with torch.no_grad():\n",
    "        # if mode == \"sam_clip\":\n",
    "        masks = mask_generator.generate(image)\n",
    "        masks = [mask for mask in masks if mask[\"area\"] < area] # area filtering based on area value from hyper-params tuning\n",
    "        img_crops = get_crops(image, masks, prompt_mode)\n",
    "        \n",
    "    return masks, img_crops\n",
    "\n",
    "def filter_sam_results(masks, img_crops):\n",
    "    new_masks, new_img_crops = [], []\n",
    "    for i in range(len(masks)):\n",
    "        mask = masks[i]\n",
    "        if mask['bbox'][0] == 0 or mask['bbox'][1] == 0:\n",
    "            continue\n",
    "        if mask['bbox'][2] <= 12 or mask['bbox'][3] <= 12:\n",
    "            continue\n",
    "        y_max, x_max = mask['bbox'][1] + mask['bbox'][3], mask['bbox'][0] + mask['bbox'][2]\n",
    "        if y_max > 253 or x_max > 253:\n",
    "            continue\n",
    "        new_masks.append(mask)\n",
    "        new_img_crops.append(img_crops[i])\n",
    "    return new_masks, new_img_crops\n",
    "\n",
    "def get_topk_similar(k, crop_scores):\n",
    "    sorted_scores = sorted([(i, m) for (i,m) in enumerate(crop_scores)], key=lambda x: x[1], reverse=True)\n",
    "    return sorted_scores[:k]\n",
    "\n",
    "def get_compelete_contour(masks):\n",
    "    width_list = []\n",
    "    # need to consider the chest xray\n",
    "    for i in masks:\n",
    "        width, height = i['bbox'][2], i['bbox'][3]\n",
    "        width_list.append(width)\n",
    "    sorted_width = sorted([(i, m) for (i,m) in  enumerate(width_list)], key=lambda x: x[1], reverse=True)\n",
    "    return sorted_width[0][1]\n",
    "\n",
    "def judge_inner_boxes(bboxes):\n",
    "    for bbox in bboxes:\n",
    "        bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_image_dict = dict()\n",
    "masks_all_image_dict = dict()\n",
    "crops_image_dict = dict()\n",
    "def generate_segments(query, image_path):\n",
    "    if masks_image_dict.__contains__(image_path):\n",
    "        masks = masks_image_dict[image_path]\n",
    "        img_crops = crops_image_dict[image_path]\n",
    "    else:\n",
    "        masks, img_crops = sam_generation(image_path=image_path)\n",
    "        masks, img_crops = filter_sam_results(masks, img_crops)\n",
    "        masks_image_dict[image_path] = masks\n",
    "        crops_image_dict[image_path] = img_crops\n",
    "    img_crops_filtered = img_crops\n",
    "    prompts = {\"query\": [query]}\n",
    "    max_indices, scores = retrieve_relevant_crop_biomed_topk(img_crops, prompts, biomed_clip_model, biomed_preprocess, config, tokenizer=tokenizer, topk=4)\n",
    "    # topk_indices = get_topk_similar(3, scores[\"query\"])\n",
    "    # define a set of rules, firstly return top3\n",
    "    # if there is no explicit organs to be used as query, then just use the whole segmentation\n",
    "    # if the smaller boxes are in the bigger box, then use all of them but assign higher weights on smaller inner boxes\n",
    "    bboxes = []\n",
    "    segs = []\n",
    "    # print(max_indices)\n",
    "    if max_indices is not None:\n",
    "        for i in max_indices[\"query\"]:\n",
    "            bboxes.append(masks[i][\"bbox\"])\n",
    "            segs.append(masks[i][\"segmentation\"])\n",
    "        return bboxes, segs, max_indices[\"query\"]\n",
    "    else:\n",
    "        return bboxes, segs, []\n",
    "\n",
    "\n",
    "def generate_all_segments(image_path):\n",
    "    if masks_all_image_dict.__contains__(image_path):\n",
    "        masks = masks_all_image_dict[image_path]\n",
    "    else:\n",
    "        masks, img_crops = sam_generation(image_path=image_path)\n",
    "        masks, img_crops = filter_sam_results(masks, img_crops)\n",
    "        masks_all_image_dict[image_path] = masks\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"/data/aofei/hallucination/IU_Xray/data_report/training.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "len(data)\n",
    "all_train_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'CXR2384_IM-0942/0.png',\n",
       " 'id': 'CXR2384_IM-0942_train0',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nAnalyze the chest X-ray and generate a concise medical report.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The heart size and pulmonary vascularity appear within normal limits. A large hiatal hernia is noted. The lungs are free of focal airspace disease. No pneumothorax or pleural effusion is seen. Degenerative changes are present in the spine.'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_en = all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "train_data_seg = copy.deepcopy(all_train_data_en)\n",
    "len(train_data_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i['image'] for i in train_data_seg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(set([i['img_name'] for i in train_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 503/2069 [23:15<1:12:32,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 734/2069 [33:56<1:01:48,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping zero-sized bounding box.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2069/2069 [1:35:55<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(train_rad_data)):\n",
    "#failure case: 432-3 + 100\n",
    "# from tqdm import tqdm\n",
    "for i in tqdm(range(len(train_data_seg))):\n",
    "# for i in tqdm(range(10)):\n",
    "    data = train_data_seg[i]\n",
    "    image_path = os.path.join(\"/data/aofei/hallucination/IU_Xray/iu_xray/images\", data[\"image\"])\n",
    "    question = \"Medical image of lungs and chest X-ray.\"\n",
    "    # question = question.split(\"The candidate Options are:\")[0]\n",
    "    # print(question)\n",
    "    query = question\n",
    "\n",
    "    bbox, segs, max_indices = [], [], []\n",
    "    try:\n",
    "        bbox, segs, max_indices = generate_segments(query, image_path)\n",
    "    except:\n",
    "        continue\n",
    "    # print(bbox)\n",
    "    data['bbox'] = bbox\n",
    "    data['mask'] = segs\n",
    "    data[\"bbox_indices\"] = max_indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7946"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(train_data_seg[0]['mask'][0])\n",
    "np.sum(train_data_seg[0]['mask'][1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for i in train_data_seg:\n",
    "    if not i.__contains__(\"mask\"):\n",
    "        s+= 1\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'CXR2887_IM-1289/0.png',\n",
       " 'id': 'CXR2887_IM-1289_train3',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nAnalyze the chest X-ray and generate a concise medical report.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'The cardiomediastinal silhouette is normal in size and contour. There are a few XXXX opacities in the lung bases bilaterally. No definitive pneumothorax or pleural effusion. Displaced fracture of the mid one-third of the right clavicle.'}],\n",
       " 'bbox': [[2, 41, 36, 48],\n",
       "  [54, 185, 14, 16],\n",
       "  [199, 105, 19, 22],\n",
       "  [42, 227, 25, 15]],\n",
       " 'mask': [array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]),\n",
       "  array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]),\n",
       "  array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]),\n",
       "  array([[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]])],\n",
       " 'bbox_indices': [3, 2, 1, 0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_seg[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'CXR3547_IM-1739/0.png',\n",
       " 'id': 'CXR3547_IM-1739_train2063',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nAnalyze the chest X-ray and generate a concise medical report.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Heart size and mediastinal contour are normal. Pulmonary vascularity is normal. Lungs are clear. No pleural effusions or pneumothoraces. Degenerative changes in the thoracic spine.'}],\n",
       " 'bboxes': [[37, 30, 170, 134],\n",
       "  [36, 36, 78, 129],\n",
       "  [143, 29, 65, 119],\n",
       "  [97, 35, 111, 141]],\n",
       " 'masks': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_train_data = []\n",
    "segments_dict = dict()\n",
    "for i in train_data_seg:\n",
    "    template = dict()\n",
    "    \n",
    "    # template['answer_type'] = i['answer_type']\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = i['id']\n",
    "    template['conversations'] = i['conversations']\n",
    "    template['bboxes'] = []\n",
    "    template['masks'] = []\n",
    "    segments_dict[str(i['id'])] = []\n",
    "    if i.__contains__(\"bbox\"):\n",
    "        template['bboxes'] = i[\"bbox\"]\n",
    "    if i.__contains__(\"mask\"):\n",
    "        segments_dict[str(i['id'])] = i[\"mask\"]\n",
    "    new_train_data.append(template)\n",
    "\n",
    "new_train_data[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data_top4 = []\n",
    "for i in new_train_data:\n",
    "    j = i.copy()\n",
    "    j[\"bboxes\"] = j[\"bboxes\"][:4]\n",
    "    new_train_data_top4.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'CXR2859_IM-1266/0.png',\n",
       " 'id': 'CXR2859_IM-1266_train99',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nAnalyze the chest X-ray and generate a concise medical report.'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'There is a rounded dense opacity in the lateral left midlung zone probably the left upper lobe most suggestive of a rounded pneumonia. There is no pleural effusion. The heart and mediastinum are normal. The skeletal structures are normal.'}],\n",
       " 'bboxes': [[30, 21, 84, 232],\n",
       "  [136, 24, 82, 228],\n",
       "  [41, 22, 72, 114],\n",
       "  [2, 28, 38, 41]],\n",
       " 'masks': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data_top4[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segments_dict['0']\n",
    "ed = 0\n",
    "for i in segments_dict:\n",
    "    if len(segments_dict[i]) == 0:\n",
    "        ed += 1\n",
    "ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the masks to npz file\n",
    "\n",
    "np.savez_compressed(\"/data/aofei/hallucination/IU_Xray/data_report/training_segments_top4.npz\", **segments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/aofei/hallucination/IU_Xray/data_report/training_masks_top4.json', 'w') as json_file:\n",
    "    json.dump(new_train_data_top4, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
