  0%|                                                                                                                                                                                                                                                                   | 0/675 [00:00<?, ?it/s]/data/aofei/conda/env/llava_v1.5/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/data/aofei/conda/env/llava_v1.5/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
torch.Size([32, 1279]) softmax
/data/aofei/conda/env/llava_v1.5/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
  0%|â–Ž                                                                                                                                                                                                                                                          | 1/675 [00:02<30:27,  2.71s/it]
{'loss': 4.5296, 'learning_rate': 9.523809523809523e-06, 'epoch': 0.0}
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
torch.Size([32, 1262]) softmax
{'loss': 6.2309, 'learning_rate': 1.9047619047619046e-05, 'epoch': 0.01}
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
{'loss': 5.7522, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.01}
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
torch.Size([32, 1276]) softmax
{'loss': 7.0981, 'learning_rate': 3.809523809523809e-05, 'epoch': 0.02}
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
{'loss': 5.467, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.02}
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
{'loss': 3.2006, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.03}
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
torch.Size([32, 1264]) softmax
{'loss': 1.9053, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.03}
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
torch.Size([32, 1268]) softmax
{'loss': 1.2987, 'learning_rate': 7.619047619047618e-05, 'epoch': 0.04}
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
torch.Size([32, 1272]) softmax
{'loss': 1.5106, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.04}
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
torch.Size([32, 1259]) softmax
{'loss': 0.8535, 'learning_rate': 9.523809523809524e-05, 'epoch': 0.04}
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
torch.Size([32, 1277]) softmax
{'loss': 1.5168, 'learning_rate': 0.00010476190476190477, 'epoch': 0.05}
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
torch.Size([32, 1260]) softmax
{'loss': 1.8158, 'learning_rate': 0.00011428571428571428, 'epoch': 0.05}
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
torch.Size([32, 1270]) softmax
{'loss': 1.685, 'learning_rate': 0.0001238095238095238, 'epoch': 0.06}
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
odict_keys(['last_hidden_state', 'attentions']) None
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
torch.Size([32, 1266]) softmax
