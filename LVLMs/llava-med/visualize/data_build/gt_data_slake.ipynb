{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "only_gt_data_path = \"/data/aofei/hallucination/Slake/data/training_gt_bboxes.json\"\n",
    "with open(only_gt_data_path, 'r') as file:\n",
    "    gt_data = json.load(file)\n",
    "\n",
    "training_path = \"/data/aofei/hallucination/Slake/data/training_masks.json\"\n",
    "with open(training_path, 'r') as file:\n",
    "    training_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': 'xmlab1/source.jpg',\n",
       "  'id': 0,\n",
       "  'location': 'Abdomen',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nWhat modality is used to take this image?'},\n",
       "   {'from': 'gpt', 'value': 'MRI'}],\n",
       "  'bboxes': [],\n",
       "  'bboxes_dict': {}},\n",
       " {'image': 'xmlab1/source.jpg',\n",
       "  'id': 0,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nWhat modality is used to take this image?'},\n",
       "   {'from': 'gpt', 'value': 'MRI'}],\n",
       "  'bboxes': [[1, 52, 238, 159],\n",
       "   [5, 59, 217, 134],\n",
       "   [115, 78, 75, 67],\n",
       "   [61, 156, 26, 31]],\n",
       "  'masks': []},\n",
       " 4919,\n",
       " 4919)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data[0], training_data[0], len(gt_data), len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(len(gt_data)):\n",
    "    gt_i = gt_data[i]\n",
    "    gt_bboxes = gt_i['bboxes']\n",
    "    training_i = training_data[i]\n",
    "    image_path = os.path.join(\"/data/aofei/hallucination/Slake/imgs\", gt_i['image'])\n",
    "    with Image.open(image_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "    new_gt_bboxes = []\n",
    "    if len(gt_bboxes) == 0:\n",
    "        training_data[i]['gt_bboxes'] = []\n",
    "        continue\n",
    "    for gt_bbox in gt_bboxes:\n",
    "        bbox = gt_bbox\n",
    "        # Original coordinates\n",
    "        top_left_x = bbox[0]\n",
    "        top_left_y = bbox[1]\n",
    "        width = bbox[2]\n",
    "        height = bbox[3]\n",
    "\n",
    "        # Calculate bottom-right coordinates\n",
    "        bottom_right_x = top_left_x + width\n",
    "        bottom_right_y = top_left_y + height\n",
    "\n",
    "        # Normalize coordinates\n",
    "        top_left_x = int(top_left_x / image_width * 256)\n",
    "        top_left_y = int(top_left_y / image_height * 256)\n",
    "        bottom_right_x = int(bottom_right_x / image_width * 256)\n",
    "        bottom_right_y = int(bottom_right_y / image_height * 256)\n",
    "        width = bottom_right_x - top_left_x\n",
    "        height = bottom_right_y - top_left_y\n",
    "\n",
    "        # Update the coordinates\n",
    "        # new_gt_bboxes.append([top_left_x, top_left_y, bottom_right_x, bottom_right_y])\n",
    "        new_gt_bboxes.append([top_left_x, top_left_y, width, height])\n",
    "    gt_i['bboxes'] = new_gt_bboxes\n",
    "    training_data[i]['gt_bboxes'] = new_gt_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4919, 611)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "import copy\n",
    "only_gt = []\n",
    "weak_label_data = []\n",
    "for i in training_data:\n",
    "    if 'gt_bboxes' in i:\n",
    "        if len(i['gt_bboxes']) > 0:\n",
    "            s += 1\n",
    "            k, p = copy.deepcopy(i), copy.deepcopy(i)\n",
    "            k['bboxes'] = i['gt_bboxes']\n",
    "            del k['gt_bboxes']\n",
    "            del k['masks']\n",
    "            only_gt.append(k)\n",
    "            del p['gt_bboxes']\n",
    "            del p['masks']\n",
    "            weak_label_data.append(p)\n",
    "\n",
    "len(training_data), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/aofei/hallucination/Slake/data/with_gt/training_only_wgt.json\"\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(only_gt, file, indent=2)\n",
    "\n",
    "save_path = \"/data/aofei/hallucination/Slake/data/with_gt/training_only_weak.json\"\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(weak_label_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': 'xmlab102/source.jpg',\n",
       "  'id': 11934,\n",
       "  'organ': 'Lung',\n",
       "  'answer_type': 'OPEN',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nWhat modality is used to take this image?'},\n",
       "   {'from': 'gpt', 'value': 'CT'}]},\n",
       " 1061)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = \"/data/aofei/hallucination/Slake/data/test.json\"\n",
    "with open(test_path, 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "test_data[0], len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Lung Cancer': [289.0, 301.0, 17.0, 22.0]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "bbox_path = os.path.join(\"/data/aofei/hallucination/Slake/imgs\", test_data[0]['image'].split(\"/\")[0], \"detection.json\")\n",
    "with open(bbox_path, 'r') as file:\n",
    "    bboxes = json.load(file)\n",
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test data\n",
    "# only_gt_data_path = \"/data/aofei/hallucination/Slake/data/training_gt_bboxes.json\"\n",
    "# with open(only_gt_data_path, 'r') as file:\n",
    "#     gt_data = json.load(file)\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "test_path = \"/data/aofei/hallucination/Slake/data/test.json\"\n",
    "with open(test_path, 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    test_i = test_data[i]\n",
    "    # test_bboxes = test_i['bboxes']\n",
    "    # training_i = training_data[i]\n",
    "    bbox_path = os.path.join(\"/data/aofei/hallucination/Slake/imgs\", test_data[i]['image'].split(\"/\")[0], \"detection.json\")\n",
    "    with open(bbox_path, 'r') as file:\n",
    "        gt_bboxes_ori = json.load(file)\n",
    "    # gt_bboxes = {}\n",
    "    # for gt_bbox in gt_bboxes_ori:\n",
    "        \n",
    "    #     gt_bboxes[gt_bbox['label']] = gt_bbox['bbox']\n",
    "    # gt_bbox_keys = list(gt_bboxes.keys())\n",
    "    test_question = test_i['conversations'][0]['value']\n",
    "    test_answer = test_i['conversations'][1]['value']\n",
    "    test_gt_bboxes = []\n",
    "    for bbox in gt_bboxes_ori:\n",
    "        k, v = list(bbox.items())[0]\n",
    "        if k.lower() in test_question.lower() or k.lower() in test_answer.lower():\n",
    "            test_gt_bboxes.append(v)\n",
    "\n",
    "    image_path = os.path.join(\"/data/aofei/hallucination/Slake/imgs\", test_i['image'])\n",
    "    with Image.open(image_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "    new_gt_bboxes = []\n",
    "    for gt_bbox in test_gt_bboxes:\n",
    "        bbox = gt_bbox\n",
    "        # Original coordinates\n",
    "        top_left_x = bbox[0]\n",
    "        top_left_y = bbox[1]\n",
    "        width = bbox[2]\n",
    "        height = bbox[3]\n",
    "\n",
    "        # Calculate bottom-right coordinates\n",
    "        bottom_right_x = top_left_x + width\n",
    "        bottom_right_y = top_left_y + height\n",
    "\n",
    "        # Normalize coordinates\n",
    "        top_left_x = int(top_left_x / image_width * 256)\n",
    "        top_left_y = int(top_left_y / image_height * 256)\n",
    "        bottom_right_x = int(bottom_right_x / image_width * 256)\n",
    "        bottom_right_y = int(bottom_right_y / image_height * 256)\n",
    "        width = bottom_right_x - top_left_x\n",
    "        height = bottom_right_y - top_left_y\n",
    "\n",
    "        # Update the coordinates\n",
    "        # new_gt_bboxes.append([top_left_x, top_left_y, bottom_right_x, bottom_right_y])\n",
    "        new_gt_bboxes.append([top_left_x, top_left_y, width, height])\n",
    "    test_i['bboxes'] = new_gt_bboxes\n",
    "    test_data[i]['gt_bboxes'] = new_gt_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_gt = []\n",
    "for i in test_data:\n",
    "    if 'gt_bboxes' in i:\n",
    "        if len(i['gt_bboxes']) > 0:\n",
    "            test_with_gt.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': 'xmlab102/source.jpg',\n",
       "  'id': 11941,\n",
       "  'organ': 'Lung',\n",
       "  'answer_type': 'OPEN',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nWhat diseases are included in the picture?'},\n",
       "   {'from': 'gpt', 'value': 'Lung Cancer'}],\n",
       "  'bboxes': [[144, 150, 9, 11]],\n",
       "  'gt_bboxes': [[144, 150, 9, 11]]},\n",
       " 206)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_with_gt[0], len(test_with_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_gt_save_path = \"/data/aofei/hallucination/Slake/data/with_gt/test_with_gt.json\"\n",
    "with open(with_gt_save_path, 'w') as file:\n",
    "    json.dump(test_with_gt, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': 'xmlab1/source.jpg',\n",
       "  'id': 0,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nWhat modality is used to take this image?'},\n",
       "   {'from': 'gpt', 'value': 'MRI'}],\n",
       "  'bboxes': [[1, 52, 238, 159],\n",
       "   [5, 59, 217, 134],\n",
       "   [115, 78, 75, 67],\n",
       "   [61, 156, 26, 31]],\n",
       "  'masks': [],\n",
       "  'gt_bboxes': []},\n",
       " 4919)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#train data\n",
    "\n",
    "train_path = \"/data/aofei/hallucination/Slake/data/with_gt/training_masks_wgt.json\"\n",
    "\n",
    "with open(train_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "train_data[0], len(train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test data\n",
    "# only_gt_data_path = \"/data/aofei/hallucination/Slake/data/training_gt_bboxes.json\"\n",
    "# with open(only_gt_data_path, 'r') as file:\n",
    "#     gt_data = json.load(file)\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_i = train_data[i]\n",
    "    # test_bboxes = test_i['bboxes']\n",
    "    # training_i = training_data[i]\n",
    "    bbox_path = os.path.join(\"/data/aofei/hallucination/Slake/imgs\", train_data[i]['image'].split(\"/\")[0], \"detection.json\")\n",
    "    with open(bbox_path, 'r') as file:\n",
    "        gt_bboxes_ori = json.load(file)\n",
    "    # gt_bboxes = {}\n",
    "    # for gt_bbox in gt_bboxes_ori:\n",
    "        \n",
    "    #     gt_bboxes[gt_bbox['label']] = gt_bbox['bbox']\n",
    "    # gt_bbox_keys = list(gt_bboxes.keys())\n",
    "    test_question = train_i['conversations'][0]['value']\n",
    "    test_answer = train_i['conversations'][1]['value']\n",
    "    test_gt_bboxes = []\n",
    "    for bbox in gt_bboxes_ori:\n",
    "        k, v = list(bbox.items())[0]\n",
    "        if k.lower() in test_question.lower() or k.lower() in test_answer.lower():\n",
    "            test_gt_bboxes.append(v)\n",
    "\n",
    "    image_path = os.path.join(\"/data/aofei/hallucination/Slake/imgs\", test_i['image'])\n",
    "    with Image.open(image_path) as img:\n",
    "        image_width, image_height = img.size\n",
    "    new_gt_bboxes = []\n",
    "    for gt_bbox in test_gt_bboxes:\n",
    "        bbox = gt_bbox\n",
    "        # Original coordinates\n",
    "        top_left_x = bbox[0]\n",
    "        top_left_y = bbox[1]\n",
    "        width = bbox[2]\n",
    "        height = bbox[3]\n",
    "\n",
    "        # Calculate bottom-right coordinates\n",
    "        bottom_right_x = top_left_x + width\n",
    "        bottom_right_y = top_left_y + height\n",
    "\n",
    "        # Normalize coordinates\n",
    "        top_left_x = int(top_left_x / image_width * 256)\n",
    "        top_left_y = int(top_left_y / image_height * 256)\n",
    "        bottom_right_x = int(bottom_right_x / image_width * 256)\n",
    "        bottom_right_y = int(bottom_right_y / image_height * 256)\n",
    "        width = bottom_right_x - top_left_x\n",
    "        height = bottom_right_y - top_left_y\n",
    "\n",
    "        # Update the coordinates\n",
    "        # new_gt_bboxes.append([top_left_x, top_left_y, bottom_right_x, bottom_right_y])\n",
    "        new_gt_bboxes.append([top_left_x, top_left_y, width, height])\n",
    "    # train_i['bboxes'] = new_gt_bboxes\n",
    "    train_data[i]['gt_bboxes'] = new_gt_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': 'xmlab1/source.jpg',\n",
       "  'id': 0,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nWhat modality is used to take this image?'},\n",
       "   {'from': 'gpt', 'value': 'MRI'}],\n",
       "  'bboxes': [[1, 52, 238, 159],\n",
       "   [5, 59, 217, 134],\n",
       "   [115, 78, 75, 67],\n",
       "   [61, 156, 26, 31]],\n",
       "  'masks': [],\n",
       "  'gt_bboxes': []},\n",
       " 4919)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4919, 992)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "import copy\n",
    "only_gt = []\n",
    "weak_label_data = []\n",
    "for i in train_data:\n",
    "    if 'gt_bboxes' in i:\n",
    "        if len(i['gt_bboxes']) > 0:\n",
    "            s += 1\n",
    "            k, p = copy.deepcopy(i), copy.deepcopy(i)\n",
    "            k['bboxes'] = i['gt_bboxes']\n",
    "            del k['gt_bboxes']\n",
    "            del k['masks']\n",
    "            only_gt.append(k)\n",
    "            del p['gt_bboxes']\n",
    "            del p['masks']\n",
    "            weak_label_data.append(p)\n",
    "\n",
    "len(train_data), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/aofei/hallucination/Slake/data/with_gt/training_only_wgt.json\"\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(only_gt, file, indent=2)\n",
    "\n",
    "save_path = \"/data/aofei/hallucination/Slake/data/with_gt/training_only_weak.json\"\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(weak_label_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992,\n",
       " 992,\n",
       " {'image': 'xmlab1/source.jpg',\n",
       "  'id': 3,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nDoes the picture contain liver?'},\n",
       "   {'from': 'gpt', 'value': 'Yes'}],\n",
       "  'bboxes': [[27, 53, 15, 15]]},\n",
       " {'image': 'xmlab1/source.jpg',\n",
       "  'id': 3,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nDoes the picture contain liver?'},\n",
       "   {'from': 'gpt', 'value': 'Yes'}],\n",
       "  'bboxes': [[1, 52, 238, 159],\n",
       "   [115, 78, 75, 67],\n",
       "   [5, 59, 217, 134],\n",
       "   [61, 156, 26, 31]]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_gt), len(weak_label_data), only_gt[0], weak_label_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
