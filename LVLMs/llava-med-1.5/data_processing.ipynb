{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2248"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/MED_RAD_test.json\", \"r\") as f:\n",
    "    rad_data = json.load(f)\n",
    "len(rad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process slake gt data\n",
    "import json\n",
    "path_wgt = \"/data/aofei/hallucination/Slake/data/with_gt/training_masks_wgt.json\"\n",
    "data_wgt = json.load(open(path_wgt, \"r\"))\n",
    "data_wgt = [i for i in data_wgt if len(i[\"gt_bboxes\"]) >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611,\n",
       " {'image': 'xmlab1/source.jpg',\n",
       "  'id': 3,\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nDoes the picture contain liver?'},\n",
       "   {'from': 'gpt', 'value': 'Yes'}],\n",
       "  'bboxes': [[1, 52, 238, 159],\n",
       "   [115, 78, 75, 67],\n",
       "   [5, 59, 217, 134],\n",
       "   [61, 156, 26, 31]],\n",
       "  'masks': [],\n",
       "  'gt_bboxes': [[54, 106, 84, 137]]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_wgt), data_wgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process slake test data\n",
    "import json\n",
    "with open(r\"/data/aofei/hallucination/Slake/data/test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]\n",
    "new_test_slake = []\n",
    "for d in test_data:\n",
    "    # if d['answer_type'] != \"OPEN\" and \"Which\" in d['conversations'][0]['value']:\n",
    "    if d['answer_type'] != \"OPEN\":\n",
    "        if \"yes\" not in d['conversations'][1]['value'].lower() and 'no' not in d['conversations'][1]['value'].lower():\n",
    "            print(d)\n",
    "            # d['answer_type'] = \"OPEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abdomen',\n",
       " 'Brain',\n",
       " 'Brain_Face',\n",
       " 'Brain_Tissue',\n",
       " 'Chest_mediastinal',\n",
       " 'Lung',\n",
       " 'Neck',\n",
       " 'Pelvic Cavity'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i['organ'] for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/data/aofei/hallucination/Slake/data/test.json\", \"w\") as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abd_data, lung_data, brain_data = [], [], []\n",
    "for i in test_data:\n",
    "    if i['organ'] == \"Abdomen\":\n",
    "        abd_data.append(i)\n",
    "    elif i['organ'] == \"Lung\":\n",
    "        lung_data.append(i)\n",
    "    elif i['organ'] == \"Brain\"\n",
    "\n",
    "with open(r\"/data/aofei/hallucination/Slake/data/test_abd.json\", \"w\") as f:\n",
    "    json.dump(abd_data, f, indent=4)\n",
    "with open(r\"/data/aofei/hallucination/Slake/data/test_lung.json\", \"w\") as f:\n",
    "    json.dump(lung_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,\n",
       " {'qid': '0',\n",
       "  'phrase_type': 'freeform',\n",
       "  'qid_linked_id': '03f451ca-de62-4617-9679-e836026a7642',\n",
       "  'image_case_url': 'https://medpix.nlm.nih.gov/case?id=48e1dd0e-8552-46ad-a354-5eb55be86de6',\n",
       "  'image_name': 'synpic54610.jpg',\n",
       "  'image_organ': 'HEAD',\n",
       "  'evaluation': 'not evaluated',\n",
       "  'question': 'Are regions of the brain infarcted?',\n",
       "  'question_rephrase': 'NULL',\n",
       "  'question_relation': 'NULL',\n",
       "  'question_frame': 'NULL',\n",
       "  'question_type': 'PRES',\n",
       "  'answer': 'Yes',\n",
       "  'answer_type': 'CLOSED'},\n",
       " 451)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rad_data = []\n",
    "test_rad_data = []\n",
    "for i in rad_data:\n",
    "    if not i['phrase_type'].startswith(\"test\"):\n",
    "        train_rad_data.append(i)\n",
    "    else:\n",
    "        test_rad_data.append(i)\n",
    "len(train_rad_data), train_rad_data[0], len(test_rad_data),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_data = []\n",
    "# img_question_id_dict = dict()\n",
    "for i in train_rad_data:\n",
    "    template = {'conversations': []}\n",
    "    img_id = i['image_name']\n",
    "    qid = i['qid']\n",
    "    new_qa = {\"from\": \"human\", \"value\": i['question']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": i['answer']}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_training_data.append(template)\n",
    "    # if img_question_id_dict.__contains__(img_id):\n",
    "    #     img_question_id_dict[img_id] += 1\n",
    "    # else:\n",
    "    #     img_question_id_dict[img_id] = 1\n",
    "    # qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'synpic31232.jpg',\n",
       " 'id': 2247,\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': 'What is the hypo-dense area seen in the vertebrae?'},\n",
       "  {'from': 'gpt', 'value': 'Nucleus Pulposus'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_train_data = []\n",
    "for i in train_rad_data:\n",
    "    template = dict()\n",
    "    \n",
    "    # template['answer_type'] = i['answer_type']\n",
    "    template['image'] = i['image_name']\n",
    "    template['id'] = i['qid']\n",
    "    template['conversations'] = []\n",
    "    # template['text'] = i['question']\n",
    "\n",
    "    new_qa = {\"from\": \"human\", \"value\": i['question']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_train_data.append(template)\n",
    "\n",
    "new_train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human',\n",
       "   'value': 'Is there cardiomegaly present?'},\n",
       "  {'from': 'gpt', 'value': 'No'}],\n",
       " 'answer_type': 'CLOSED',\n",
       " 'image': 'synpic676.jpg',\n",
       " 'id': 1998,\n",
       " 'text': 'Is there cardiomegaly present?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data = []\n",
    "for i in test_rad_data:\n",
    "    template = dict()\n",
    "    template['conversations'] = []\n",
    "    template['answer_type'] = i['answer_type']\n",
    "    template['image'] = i['image_name']\n",
    "    template['id'] = i['qid']\n",
    "    template['text'] = i['question']\n",
    "\n",
    "    new_qa = {\"from\": \"human\", \"value\": i['question']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": i['answer']}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_test_data.append(template)\n",
    "\n",
    "new_test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test_data),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'synpic54610.jpg',\n",
       " 'id': '0',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': 'Are regions of the brain infarcted?'},\n",
       "  {'from': 'gpt', 'value': 'Yes'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/training.json\", \"w\") as f:\n",
    "    json.dump(new_train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/test.json\", \"w\") as f:\n",
    "    json.dump(new_test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_train_data:\n",
    "    conv = i[\"conversations\"]\n",
    "    value1 = conv[0]['value']\n",
    "    value2 = conv[1]['value']\n",
    "    if type(value1) == int or type(value2) == int:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new VQA-RAD\n",
    "import json\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/training_bboxes.json\", \"r\") as f:\n",
    "    rad_train = json.load(f)\n",
    "len(rad_train)\n",
    "\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/test.json\", \"r\") as f:\n",
    "    rad_test = json.load(f)\n",
    "len(rad_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': 'synpic54610.jpg',\n",
       "  'id': '0',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nAre regions of the brain infarcted?'},\n",
       "   {'from': 'gpt', 'value': 'Yes'}],\n",
       "  'bboxes': [[22, 13, 189, 217],\n",
       "   [103, 15, 107, 208],\n",
       "   [23, 17, 100, 212],\n",
       "   [55, 130, 26, 26]]},\n",
       " {'conversations': [{'from': 'human',\n",
       "    'value': 'Is there evidence of an aortic aneurysm?'},\n",
       "   {'from': 'gpt', 'value': 'yes'}],\n",
       "  'answer_type': 'CLOSED',\n",
       "  'image': 'synpic42202.jpg',\n",
       "  'id': 10,\n",
       "  'text': 'Is there evidence of an aortic aneurysm?'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rad_train[0], rad_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test data\n",
    "new_test_rad = []\n",
    "for d in rad_test:\n",
    "    # if d['answer_type'] != \"OPEN\" and \"Which\" in d['conversations'][0]['value']:\n",
    "    if d['answer_type'] != \"OPEN\":\n",
    "        if \"yes\" not in d['conversations'][1]['value'].lower() and 'no' not in d['conversations'][1]['value'].lower():\n",
    "            print(d)\n",
    "            # d['answer_type'] = \"OPEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/test.json\", \"w\") as f:\n",
    "    json.dump(rad_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': '0',\n",
       " 'phrase_type': 'freeform',\n",
       " 'qid_linked_id': '03f451ca-de62-4617-9679-e836026a7642',\n",
       " 'image_case_url': 'https://medpix.nlm.nih.gov/case?id=48e1dd0e-8552-46ad-a354-5eb55be86de6',\n",
       " 'image_name': 'synpic54610.jpg',\n",
       " 'image_organ': 'HEAD',\n",
       " 'evaluation': 'not evaluated',\n",
       " 'question': 'Are regions of the brain infarcted?',\n",
       " 'question_rephrase': 'NULL',\n",
       " 'question_relation': 'NULL',\n",
       " 'question_frame': 'NULL',\n",
       " 'question_type': 'PRES',\n",
       " 'answer': 'Yes',\n",
       " 'answer_type': 'CLOSED'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new training data\n",
    "# for i in train_rad_data:\n",
    "train_rad_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([i['image_organ'] for i in train_rad_data])\n",
    "abd_ids, chest_ids, head_ids = [], [], []\n",
    "for i in train_rad_data:\n",
    "    if i['image_organ'] == \"ABD\":\n",
    "        abd_ids.append(i['qid'])\n",
    "    elif i['image_organ'] == \"CHEST\":\n",
    "        chest_ids.append(i['qid'])\n",
    "    else:\n",
    "        head_ids.append(i['qid'])\n",
    "\n",
    "set([i['image_organ'] for i in test_rad_data])\n",
    "test_abd_ids, test_chest_ids, test_head_ids = [], [], []\n",
    "for i in test_rad_data:\n",
    "    if i['image_organ'] == \"ABD\":\n",
    "        test_abd_ids.append(i['qid'])\n",
    "    elif i['image_organ'] == \"CHEST\":\n",
    "        test_chest_ids.append(i['qid'])\n",
    "    else:\n",
    "        test_head_ids.append(i['qid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581, 596, 620, 158, 119, 174)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abd_ids), len(head_ids), len(chest_ids), len(test_abd_ids), len(test_head_ids), len(test_chest_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rad_train), len(rad_test)\n",
    "rad_train_abd, rad_train_chest, rad_train_head = [], [], []\n",
    "for i in rad_train:\n",
    "    _id = i['id']\n",
    "    if _id in abd_ids:\n",
    "        rad_train_abd.append(i)\n",
    "    elif _id in chest_ids:\n",
    "        rad_train_chest.append(i)\n",
    "    else:\n",
    "        rad_train_head.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/training_bboxes_abd.json\", \"w\") as f:\n",
    "    json.dump(rad_train_abd, f, indent=4)\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/training_bboxes_lung.json\", \"w\") as f:\n",
    "    json.dump(rad_train_chest, f, indent=4)\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/training_bboxes_head.json\", \"w\") as f:\n",
    "    json.dump(rad_train_head, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451,\n",
       " {'conversations': [{'from': 'human',\n",
       "    'value': 'Is there evidence of an aortic aneurysm?'},\n",
       "   {'from': 'gpt', 'value': 'yes'}],\n",
       "  'answer_type': 'CLOSED',\n",
       "  'image': 'synpic42202.jpg',\n",
       "  'id': 10,\n",
       "  'text': 'Is there evidence of an aortic aneurysm?'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rad_test), rad_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_test_abd, rad_test_chest, rad_test_head = [], [], []\n",
    "for i in rad_test:\n",
    "    _id = i['id']\n",
    "    if _id in test_abd_ids:\n",
    "        rad_test_abd.append(i)\n",
    "    elif _id in test_chest_ids:\n",
    "        rad_test_chest.append(i)\n",
    "    else:\n",
    "        rad_test_head.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rad_test_abd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/test_abd.json\", \"w\") as f:\n",
    "    json.dump(rad_test_abd, f, indent=4)\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/test_lung.json\", \"w\") as f:\n",
    "    json.dump(rad_test_chest, f, indent=4)\n",
    "with open(r\"/data/aofei/hallucination/VQA_RAD/data/test_head.json\", \"w\") as f:\n",
    "    json.dump(rad_test_head, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data sampleing for few-shot tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data has been saved to /data/aofei/hallucination/Slake/data/few_shot/training_masks_1%.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Load the JSON file\n",
    "input_file = '/data/aofei/hallucination/Slake/data/training_masks.json'  # Replace with your input file path\n",
    "output_file = '/data/aofei/hallucination/Slake/data/few_shot/training_masks_1%.json'  # Replace with your desired output file path\n",
    "sample_ratio = 0.01  # Ratio of data to sample\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(input_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Ensure the data is a list of dictionaries\n",
    "if isinstance(data, list):\n",
    "    # Sample the data\n",
    "    sampled_data = random.sample(data, int(len(data) * sample_ratio))\n",
    "\n",
    "    # Save the sampled data to a new JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(sampled_data, outfile, indent=4)\n",
    "\n",
    "    print(f\"Sampled data has been saved to {output_file}\")\n",
    "else:\n",
    "    print(\"The JSON file does not contain a list of dictionaries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path vqa\n",
    "training_path = \"/data/aofei/hallucination/PathVQA/pvqa/train.json\"\n",
    "test_path = \"/data/aofei/hallucination/PathVQA/pvqa/test.json\"\n",
    "\n",
    "import json\n",
    "with open(training_path, \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(test_path, \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'train_0422.jpg',\n",
       " 'id': 100422000,\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': 'Where are liver stem cells (oval cells) located?'},\n",
       "  {'from': 'gpt', 'value': 'in the canals of hering'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 100533001,\n",
       " 'image_name': 'train_0533.jpg',\n",
       " 'answer': 'yes',\n",
       " 'answer_type': 'yes/no',\n",
       " 'question_type': 'is',\n",
       " 'question': 'Is embolus derived from a lower-extremity deep venous thrombus lodged in a pulmonary artery branch?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9806, 19755)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_data = []\n",
    "for i in train_data:\n",
    "    if i['answer'].lower() == \"yes\" or i['answer'].lower() == \"no\":\n",
    "        closed_data.append(i)\n",
    "len(closed_data), len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_data:\n",
    "    if i['answer'].lower() == \"yes\" or i['answer'].lower() == \"no\":\n",
    "        i['answer_type'] = \"CLOSED\"\n",
    "    else:\n",
    "        i['answer_type'] = \"OPEN\"\n",
    "\n",
    "with open(test_path, \"w\") as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'train_2584.jpg',\n",
       " 'id': 102584003,\n",
       " 'conversations': [{'from': 'human', 'value': 'Where is this?'},\n",
       "  {'from': 'gpt', 'value': 'urinary'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_train_data = []\n",
    "for i in train_data:\n",
    "    template = dict()\n",
    "    \n",
    "    # template['answer_type'] = i['answer_type']\n",
    "    template['image'] = i['image_name']\n",
    "    template['id'] = i['qid']\n",
    "    template['conversations'] = []\n",
    "    # template['text'] = i['question']\n",
    "\n",
    "    new_qa = {\"from\": \"human\", \"value\": i['question']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_train_data.append(template)\n",
    "\n",
    "new_train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_path, \"w\") as f:\n",
    "    json.dump(new_train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 300167000,\n",
       " 'image_name': 'test_0167.jpg',\n",
       " 'answer': 'the histone subunits',\n",
       " 'answer_type': 'OPEN',\n",
       " 'question_type': 'what',\n",
       " 'question': 'What are positively charged,  thus allowing the compaction of the negatively charged DNA?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human', 'value': 'Where is this?'},\n",
       "  {'from': 'gpt', 'value': 'urinary'}],\n",
       " 'answer_type': 'OPEN',\n",
       " 'image': 'test_0648.jpg',\n",
       " 'id': 300648006,\n",
       " 'text': 'Where is this?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data = []\n",
    "for i in test_data:\n",
    "    template = dict()\n",
    "    template['conversations'] = []\n",
    "    template['answer_type'] = i['answer_type']\n",
    "    template['image'] = i['image_name']\n",
    "    template['id'] = i['qid']\n",
    "    template['text'] = i['question']\n",
    "\n",
    "    new_qa = {\"from\": \"human\", \"value\": i['question']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": i['answer']}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_test_data.append(template)\n",
    "\n",
    "new_test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, \"w\") as f:\n",
    "    json.dump(new_test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
