{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(jsonl_path, test_size=0.8, random_state=2024):\n",
    "    # Read the jsonl file\n",
    "    with open(jsonl_path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    \n",
    "    # Extract the images\n",
    "    images = list(set([item['image'] for item in data]))\n",
    "    \n",
    "    # Split the data\n",
    "    train_images, test_images = train_test_split(images, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Create training and test sets\n",
    "    train_data = [item for item in data if item['image'] in train_images]\n",
    "    test_data = [item for item in data if item['image'] in test_images]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Example usage\n",
    "jsonl_path = '/data/aofei/hallucination/CARES/HAM10000/HAM10000_factuality.jsonl'\n",
    "ham_train_data, ham_test_data = split_data(jsonl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,\n",
       " 1600,\n",
       " {'question_id': 'ISIC_0034761',\n",
       "  'options': 'A:scalp, B:ear, C:upper extremity, D:lower extremity',\n",
       "  'fig_caption': 'C:upper extremity',\n",
       "  'age': 45,\n",
       "  'gender': 'female',\n",
       "  'image': 'ham10000_testset/ISIC_0034761.jpg',\n",
       "  'text': \"This is a medical Question with several Options, and there is only one correct answer among these options. Please select the correct answer for the question. Remember, you can only select one option. The Question is:Which part of the body's skin is affected by pigmented lesion in this dermoscopy image?The candidate Options are:[A:scalp, B:ear, C:upper extremity, D:lower extremity]\\n\"})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_train_data), len(ham_test_data), ham_train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'ham10000_testset/ISIC_0035481.jpg',\n",
       " 'id': 'ISIC_0035481_train399',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nThis is a medical Question with several Options, and there is only one correct answer among these options. Please select the correct answer for the question. Remember, you can only select one option. The Question is:What part of the body does the lesion in the image appear on?The candidate Options are:[A:trunk, B:face, C:ear, D:lower extremity]\\n'},\n",
       "  {'from': 'gpt', 'value': 'D:lower extremity'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_ham_train_data = []\n",
    "s = 0\n",
    "for i in ham_train_data:\n",
    "    template = dict()\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = i['question_id'] + \"_train\" + str(s)\n",
    "    template['conversations'] = []\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['text']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['fig_caption'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_ham_train_data.append(template)\n",
    "    s+=1\n",
    "\n",
    "new_ham_train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nThis is a medical Question with several Options, and there is only one correct answer among these options. Please select the correct answer for the question. Remember, you can only select one option. The Question is:What type of abnormality is present in this image?The candidate Options are:[A:vascular lesions, B:basal cell carcinoma, C:melanocytic nevi, D:benign keratosis-like lesions]\\n'},\n",
       "  {'from': 'gpt', 'value': 'C:melanocytic nevi'}],\n",
       " 'answer_type': 'CLOSED',\n",
       " 'image': 'ham10000_testset/ISIC_0034672.jpg',\n",
       " 'id': 'ISIC_0034672_test1599'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ham_test_data = []\n",
    "s = 0\n",
    "for i in ham_test_data:\n",
    "    template = dict()\n",
    "    template['conversations'] = []\n",
    "    template['answer_type'] = \"CLOSED\"\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = i['question_id'] + \"_test\" + str(s)\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['text']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": i['fig_caption']}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_ham_test_data.append(template)\n",
    "    s += 1\n",
    "\n",
    "new_ham_test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "train_path = '/data/aofei/hallucination/CARES/HAM10000/training.json'\n",
    "test_path = '/data/aofei/hallucination/CARES/HAM10000/test.json'\n",
    "# Save training data\n",
    "with open(train_path, 'w') as train_file:\n",
    "    json.dump(new_ham_train_data, train_file, indent=4)\n",
    "\n",
    "# Save test data\n",
    "with open(test_path, 'w') as test_file:\n",
    "    json.dump(new_ham_test_data, test_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IU-Xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path = '/data/aofei/hallucination/CARES/IU-Xray/iuxray_factuality.jsonl'\n",
    "iu_train_data, iu_test_data = split_data(jsonl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, set())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = [i['image'] for i in iu_train_data]\n",
    "test_images = [i['image'] for i in iu_test_data]\n",
    "len(train_images), len(test_images)\n",
    "common_images = set(train_images).intersection(set(test_images))\n",
    "len(common_images), common_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1789,\n",
       " 784,\n",
       " {'question': 'Does the cardiomediastinal silhouette appear normal in the chest X-ray? Please choose from the following two options: [yes, no]\\n<image>',\n",
       "  'answer': 'Yes.',\n",
       "  'image': 'CXR3030_IM-1405/0.png',\n",
       "  'question_id': 0,\n",
       "  'text': 'Does the cardiomediastinal silhouette appear normal in the chest X-ray? Please choose from the following two options: [yes, no]\\n<image>'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iu_train_data), len(iu_test_data), iu_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'CXR49_IM-2110/0.png',\n",
       " 'id': '0_train1788',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nAre the mediastinal contours within normal limits? Please choose from the following two options: [yes, no]'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Yes, since the report does not mention any abnormalities of the mediastinum.'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qs = qs.replace(DEFAULT_IMAGE_TOKEN, '').strip()\n",
    "\n",
    "#training2\n",
    "new_iu_train_data = []\n",
    "s = 0\n",
    "for i in iu_train_data:\n",
    "    template = dict()\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = str(i['question_id']) + \"_train\" + str(s)\n",
    "    template['conversations'] = []\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['question'].replace(\"<image>\", '').strip()}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_iu_train_data.append(template)\n",
    "    s+=1\n",
    "\n",
    "new_iu_train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nDoes the patient have a pleural effusion according to the X-ray? Please choose from the following two options: [yes, no]'},\n",
       "  {'from': 'gpt', 'value': 'No.'}],\n",
       " 'answer_type': 'CLOSED',\n",
       " 'image': 'CXR1708_IM-0466/0.png',\n",
       " 'id': '0_test783'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_iu_test_data = []\n",
    "s = 0\n",
    "for i in iu_test_data:\n",
    "    template = dict()\n",
    "    template['conversations'] = []\n",
    "    template['answer_type'] = \"CLOSED\"\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = str(i['question_id']) + \"_test\" + str(s)\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['question'].replace(\"<image>\", '').strip()}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": i['answer']}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_iu_test_data.append(template)\n",
    "    s += 1\n",
    "\n",
    "new_iu_test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "train_path = '/data/aofei/hallucination/CARES/IU-Xray/training.json'\n",
    "test_path = '/data/aofei/hallucination/CARES/IU-Xray/test.json'\n",
    "# Save training data\n",
    "print(len(new_iu_train_data))\n",
    "with open(train_path, 'w') as train_file:\n",
    "    json.dump(new_iu_train_data, train_file, indent=4)\n",
    "\n",
    "# Save test data\n",
    "print(len(new_iu_test_data))\n",
    "with open(test_path, 'w') as test_file:\n",
    "    json.dump(new_iu_test_data, test_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OminiVQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dataset': 'Adam Challenge',\n",
       "  'question_id': 'Adam Challenge_0000',\n",
       "  'question_type': 'Modality Recognition',\n",
       "  'option_A': 'X-ray imaging',\n",
       "  'option_B': 'Fundus photography',\n",
       "  'option_C': 'Ultrasound imaging',\n",
       "  'option_D': 'Magnetic resonance imaging (MRI)',\n",
       "  'modality_type': 'Fundus Photography',\n",
       "  'text': 'What imaging technique is employed to acquire this fundus image?',\n",
       "  'question_idx': 1,\n",
       "  'answer': 'Fundus photography',\n",
       "  'image': 'Images/Adam Challenge/AMD/A0017.jpg'},\n",
       " 12227)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "data_path = \"/data/aofei/hallucination/CARES/OmniMedVQA/omnimedvqa_factuality.jsonl\"\n",
    "with open(data_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "data[0], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8797"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_iamge = []\n",
    "for i in data:\n",
    "    image_path = os.path.join(\"/data/aofei/hallucination/OmniMedVQA/VQA/raw/OmniMedVQA\", i['image'])\n",
    "    if os.path.exists(image_path):\n",
    "        data_w_iamge.append(i)\n",
    "len(data_w_iamge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, test_size=0.3, random_state=2024):\n",
    "    # Extract the images\n",
    "    images = list(set([item['image'] for item in data]))\n",
    "    \n",
    "    # Split the data\n",
    "    train_images, test_images = train_test_split(images, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Create training and test sets\n",
    "    train_data = [item for item in data if item['image'] in train_images]\n",
    "    test_data = [item for item in data if item['image'] in test_images]\n",
    "    \n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_train_data, omni_test_data = split_data(data_w_iamge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6155,\n",
       " 2642,\n",
       " {'dataset': 'Adam Challenge',\n",
       "  'question_id': 'Adam Challenge_0000',\n",
       "  'question_type': 'Modality Recognition',\n",
       "  'option_A': 'X-ray imaging',\n",
       "  'option_B': 'Fundus photography',\n",
       "  'option_C': 'Ultrasound imaging',\n",
       "  'option_D': 'Magnetic resonance imaging (MRI)',\n",
       "  'modality_type': 'Fundus Photography',\n",
       "  'text': 'What imaging technique is employed to acquire this fundus image?',\n",
       "  'question_idx': 1,\n",
       "  'answer': 'Fundus photography',\n",
       "  'image': 'Images/Adam Challenge/AMD/A0017.jpg'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(omni_train_data), len(omni_test_data), omni_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Anatomy Identification',\n",
       "  'Disease Diagnosis',\n",
       "  'Lesion Grading',\n",
       "  'Modality Recognition'},\n",
       " {'Anatomy Identification',\n",
       "  'Disease Diagnosis',\n",
       "  'Lesion Grading',\n",
       "  'Modality Recognition'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([item['question_type'] for item in omni_train_data]), set([item['question_type'] for item in omni_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'Images/MIAS/mdb248.png',\n",
       " 'id': 'MIAS_0141_train6154',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat is the depicted abnormality in this image? options: Calcification, Hypertrophy, Ischemia, Hyperplasia'},\n",
       "  {'from': 'gpt', 'value': 'Calcification'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_omni_train_data = []\n",
    "s = 0\n",
    "for i in omni_train_data:\n",
    "    template = dict()\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = i['question_id'] + \"_train\" + str(s)\n",
    "    template['conversations'] = []\n",
    "    options = []\n",
    "    for j in i.keys():\n",
    "        if 'option' in j.lower():\n",
    "            options.append(i[j])\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['text'] + \" options: \" + \", \".join(options)}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_omni_train_data.append(template)\n",
    "    s+=1\n",
    "\n",
    "new_omni_train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'Images/MIAS/mdb214.png',\n",
       " 'id': 'MIAS_0140_train2641',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat is the depicted abnormality in this image? options: Aneurysm, Hyperplasia, Calcification, Apoptosis'},\n",
       "  {'from': 'gpt', 'value': 'Calcification'}],\n",
       " 'option_A': 'Aneurysm',\n",
       " 'option_B': 'Hyperplasia',\n",
       " 'option_C': 'Calcification',\n",
       " 'option_D': 'Apoptosis'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_omni_test_data = []\n",
    "s = 0\n",
    "for i in omni_test_data:\n",
    "    template = dict()\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = i['question_id'] + \"_train\" + str(s)\n",
    "    template['conversations'] = []\n",
    "    options = []\n",
    "    for j in i.keys():\n",
    "        if 'option' in j.lower():\n",
    "            template[j] = i[j]\n",
    "            options.append(i[j])\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['text'] + \" options: \" + \", \".join(options)}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_omni_test_data.append(template)\n",
    "    s+=1\n",
    "\n",
    "new_omni_test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6155\n",
      "2642\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "train_path = '/data/aofei/hallucination/CARES/OmniMedVQA/training.json'\n",
    "test_path = '/data/aofei/hallucination/CARES/OmniMedVQA/test.json'\n",
    "# Save training data\n",
    "print(len(new_omni_train_data))\n",
    "with open(train_path, 'w') as train_file:\n",
    "    json.dump(new_omni_train_data, train_file, indent=2)\n",
    "\n",
    "# Save test data\n",
    "print(len(new_omni_test_data))\n",
    "with open(test_path, 'w') as test_file:\n",
    "    json.dump(new_omni_test_data, test_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "s = 0\n",
    "for i in new_omni_train_data:\n",
    "    image_path = os.path.join('/data/aofei/hallucination/OmniMedVQA/VQA/raw/OmniMedVQA', i['image'])\n",
    "    if os.path.exists(image_path):\n",
    "        s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6155"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2642"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "s = 0\n",
    "for i in new_omni_test_data:\n",
    "    image_path = os.path.join('/data/aofei/hallucination/OmniMedVQA/VQA/raw/OmniMedVQA', i['image'])\n",
    "    if os.path.exists(image_path):\n",
    "        s += 1\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OL3I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Open the file in read mode\n",
    "with h5py.File('/data/aofei/hallucination/OL3I/l3_slices.h5', 'r') as file:\n",
    "    # List all groups\n",
    "    all_images_keys = list(file.keys())\n",
    "    all_images = [file[key] for key in all_images_keys]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the file in read mode again to access the datasets\n",
    "# with h5py.File('/data/aofei/hallucination/OL3I/l3_slices.h5', 'r') as file:\n",
    "#     # Access and plot the first image as an example\n",
    "#     first_image_key = all_images_keys[0]\n",
    "#     first_image = file[first_image_key][:]\n",
    "    \n",
    "#     plt.imshow(first_image, cmap='gray')\n",
    "#     plt.title(first_image_key)\n",
    "#     plt.show()\n",
    "#     # Create a directory to save the images if it doesn't exist\n",
    "output_dir = '/data/aofei/hallucination/OL3I/images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the file in read mode again to access the datasets\n",
    "with h5py.File('/data/aofei/hallucination/OL3I/l3_slices.h5', 'r') as file:\n",
    "    for key in all_images_keys:\n",
    "        image_data = file[key][:]\n",
    "        image = Image.fromarray(image_data)\n",
    "        image = image.convert(\"L\")  # Convert to grayscale\n",
    "        image.save(os.path.join(output_dir, f\"{key}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['++NebvqGlMvCY5fNgoWqlPElDnew7MwkpQQgEATyhig=',\n",
       " '+0Hfk5_grXym69lMrp787ms41mZMAsOz+i9Dqt93baQ=',\n",
       " '+0OU1HKapBJZ2NTVTdN+F6jwSYooBJ0nDNG0TBA96hk=',\n",
       " '+0UEWiPmWjBh4_AYZvUyc5k8EZaJvKMrOCRXPmHoVFc=',\n",
       " '+0dgX7nnfhWN8PdzMFf2Msq3SR002Vapppq07JaJ+mU=']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(list(file.keys()))\n",
    "all_images_keys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Closed HDF5 dataset>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'label': 0,\n",
       "  'age': '68',\n",
       "  'gender': 'male',\n",
       "  'options': 'A:Yes, B:No',\n",
       "  'answer': 'B:No',\n",
       "  'question_id': 0,\n",
       "  'text': 'Is ischemic heart disease detectable in this image? Please choose from the following two options: [yes, no]\\n',\n",
       "  'image': '5ov_JwsspJDgR9XHCiwCAqha6xvI+OhXz67m_tH4nyA=.jpg'},\n",
       " 1000)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "data_path = \"/data/aofei/hallucination/CARES/OL3I/OL3I_factuality.jsonl\"\n",
    "with open(data_path, 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "data[0], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_iamge = []\n",
    "for i in data:\n",
    "    image_path = os.path.join('/data/aofei/hallucination/OL3I/images', i['image'])\n",
    "    if os.path.exists(image_path):\n",
    "        data_w_iamge.append(i)\n",
    "len(data_w_iamge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(data, test_size=0.9, random_state=2024):\n",
    "    # Extract the images\n",
    "    images = list(set([item['image'] for item in data]))\n",
    "    \n",
    "    # Split the data\n",
    "    train_images, test_images = train_test_split(images, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Create training and test sets\n",
    "    train_data = [item for item in data if item['image'] in train_images]\n",
    "    test_data = [item for item in data if item['image'] in test_images]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "ol_train_data, ol_test_data = split_data(data_w_iamge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " 900,\n",
       " {'label': 0,\n",
       "  'age': '40',\n",
       "  'gender': 'male',\n",
       "  'options': 'A:FRS and PCE, B:No specific types of abnormalities',\n",
       "  'answer': 'B:No specific types of abnormalities',\n",
       "  'question_id': 0,\n",
       "  'text': 'What risk assessment methods can detect the specific type of pathological abnormalities shown in the images? Please choose from the following two options: [FRS and PCE, No specific types of abnormalities]\\n',\n",
       "  'image': 'qceAhHdhsVd4hnrgyjuMvEdppsy5U3XBXVDMM+qstzQ=.jpg'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ol_train_data), len(ol_test_data), ol_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'age': '40',\n",
       " 'gender': 'male',\n",
       " 'options': 'A:FRS and PCE, B:No specific types of abnormalities',\n",
       " 'answer': 'B:No specific types of abnormalities',\n",
       " 'question_id': 0,\n",
       " 'text': 'What risk assessment methods can detect the specific type of pathological abnormalities shown in the images? Please choose from the following two options: [FRS and PCE, No specific types of abnormalities]\\n',\n",
       " 'image': 'qceAhHdhsVd4hnrgyjuMvEdppsy5U3XBXVDMM+qstzQ=.jpg',\n",
       " 'text2': 'What risk assessment methods can detect the specific type of pathological abnormalities shown in the images? Options: A:FRS and PCE, B:No specific types of abnormalities',\n",
       " 'answer2': 'B:No specific types of abnormalities'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ol_train_data:\n",
    "    if \"Please choose from\" in i['text']:\n",
    "        question = i['text'].split(\"Please choose from\")[0].strip()\n",
    "        if \"yes\" in i['options'].lower() and \"no\" in i['options'].lower():\n",
    "            # if \"yes\" in i['answer'].lower():\n",
    "            #     answer = \"Yes\"\n",
    "            # else:\n",
    "            #     answer = \"No\"\n",
    "            answer = i['answer'].split(\":\")[-1].strip()\n",
    "        else:\n",
    "            question += \" Options: \" + i['options']\n",
    "            answer = i['answer']\n",
    "    else:\n",
    "        question = i['text']\n",
    "        if \"yes\" in i['options'].lower() and \"no\" in i['options'].lower():\n",
    "            # if \"yes\" in i['answer'].lower():\n",
    "            #     answer = \"Yes\"\n",
    "            # else:\n",
    "            #     answer = \"No\"\n",
    "            answer = i['answer'].split(\":\")[-1].strip()\n",
    "        else:\n",
    "            question += \" Options: \" + i['options']\n",
    "            answer = i['answer']\n",
    "    i['text2'] = question\n",
    "    i['answer2'] = answer\n",
    "    \n",
    "ol_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the image of the third lumbar vertebra show any signs of ischemic changes that would be consistent with Ischemic Heart Disease?\n",
      "Does the axial image of the third lumbar vertebra present any visual indicators of heart-related conditions that could be indicative of Ischemic Heart Disease?\n",
      "What does this axial image of the third lumbar vertebra contain that can help detect Ischemic Heart Disease? Options: A:Body composition imaging biomarkers for atherosclerotic cardiovascular disease, B:None\n",
      "What does the axial image of the third lumbar vertebra indicate regarding the risk of Ischemic Heart Disease? Options: A:Increased risk, B:No indication of increased risk\n",
      "What is the presence of any abnormal findings in the axial image of the third lumbar vertebra that could be related to Ischemic Heart Disease? Options: A:Abnormal findings are present, B:No abnormal findings related to Ischemic Heart Disease are present\n",
      "Is there any correlation between the findings in this axial image of the third lumbar vertebra and Ischemic Heart Disease?\n",
      "What is the presence of any abnormal findings in the axial image of the third lumbar vertebra that could be related to Ischemic Heart Disease? Options: A:Abnormal findings are present, B:No abnormal findings related to Ischemic Heart Disease are present\n",
      "At 1 year follow-up, was the diagnosis of ischaemic heart disease positive for the individuals represented in the images?\n",
      "Is there any correlation between the findings in this axial image of the third lumbar vertebra and Ischemic Heart Disease?\n",
      "What is the presence of any abnormal findings in the axial image of the third lumbar vertebra that could be related to Ischemic Heart Disease? Options: A:Abnormal findings are present, B:No abnormal findings related to Ischemic Heart Disease are present\n"
     ]
    }
   ],
   "source": [
    "for i in ol_train_data[10:20]:\n",
    "    print(i['text2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': '7G28zEItafhQshce03rtbUoQihMrZB19M2wLSa+WORE=.jpg',\n",
       " 'id': '0_train99',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nAt 1 year follow-up, was the diagnosis of ischaemic heart disease negative for the individuals represented in the images?'},\n",
       "  {'from': 'gpt', 'value': 'Yes'}],\n",
       " 'options': 'A:No, B:Yes'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training2\n",
    "new_ol_train_data = []\n",
    "s = 0\n",
    "for i in ol_train_data:\n",
    "    template = dict()\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = str(i['question_id']) + \"_train\" + str(s)\n",
    "    template['conversations'] = []\n",
    "    options = i['options']\n",
    "    template['options'] = options\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['text2']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer2'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_ol_train_data.append(template)\n",
    "    s+=1\n",
    "\n",
    "new_ol_train_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'EKyv7Swd6fmLvNJbJVUP4qIvp4qwPkrUT8oKiogdBJs=.jpg',\n",
       " 'id': '0_train20',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nWhat is the likelihood of detecting Ischemic Heart Disease from the image of the third lumbar vertebra? Options: A:High, B:Low to none'},\n",
       "  {'from': 'gpt', 'value': 'B:Low to none'}],\n",
       " 'options': 'A:High, B:Low to none'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ol_train_data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'age': '68',\n",
       " 'gender': 'male',\n",
       " 'options': 'A:Yes, B:No',\n",
       " 'answer': 'B:No',\n",
       " 'question_id': 0,\n",
       " 'text': 'Is ischemic heart disease detectable in this image? Please choose from the following two options: [yes, no]\\n',\n",
       " 'image': '5ov_JwsspJDgR9XHCiwCAqha6xvI+OhXz67m_tH4nyA=.jpg',\n",
       " 'text2': 'Is ischemic heart disease detectable in this image?',\n",
       " 'answer2': 'No'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ol_test_data:\n",
    "    if \"Please choose from\" in i['text']:\n",
    "        question = i['text'].split(\"Please choose from\")[0].strip()\n",
    "        if \"yes\" in i['options'].lower() and \"no\" in i['options'].lower():\n",
    "            # if \"yes\" in i['answer'].lower():\n",
    "            #     answer = \"Yes\"\n",
    "            # else:\n",
    "            #     answer = \"No\"\n",
    "            answer = i['answer'].split(\":\")[-1].strip()\n",
    "        else:\n",
    "            question += \" Options: \" + i['options']\n",
    "            answer = i['answer']\n",
    "    else:\n",
    "        question = i['text']\n",
    "        if \"yes\" in i['options'].lower() and \"no\" in i['options'].lower():\n",
    "            # if \"yes\" in i['answer'].lower():\n",
    "            #     answer = \"Yes\"\n",
    "            # else:\n",
    "            #     answer = \"No\"\n",
    "            answer = i['answer'].split(\":\")[-1].strip()\n",
    "        else:\n",
    "            question += \" Options: \" + i['options']\n",
    "            answer = i['answer']\n",
    "    i['text2'] = question\n",
    "    i['answer2'] = answer\n",
    "    \n",
    "ol_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'RyRzTqEcHscVjMw1ycPoMtF_PZEyCmr0TqK0xO1smn4=.jpg',\n",
       " 'id': '0_test899',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nDoes the axial image of the third lumbar vertebra show any signs of aortic atherosclerosis, which is associated with Ischemic Heart Disease?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'No, there is no sign of aortic atherosclerosis in the image'}],\n",
       " 'option_A': 'A:Yes',\n",
       " 'option_B': ' there is visible aortic atherosclerosis',\n",
       " 'option_C': ' B:No',\n",
       " 'option_D': ' there is no sign of aortic atherosclerosis in the image'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ol_test_data = []\n",
    "s = 0\n",
    "for i in ol_test_data:\n",
    "    template = dict()\n",
    "    template['image'] = i['image']\n",
    "    template['id'] = str(i['question_id']) + \"_test\" + str(s)\n",
    "    template['conversations'] = []\n",
    "    Options_str = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    for j in range(len(i['options'].split(\",\"))):\n",
    "        template[\"option_\"+Options_str[j]] = i['options'].split(\",\")[j]\n",
    "    new_qa = {\"from\": \"human\", \"value\": \"<image>\\n\" + i['text2']}\n",
    "    new_qa2 = {\"from\": \"gpt\", \"value\": str(i['answer2'])}\n",
    "    template['conversations'] += [new_qa, new_qa2]\n",
    "    new_ol_test_data.append(template)\n",
    "    s+=1\n",
    "\n",
    "new_ol_test_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 't7G2__0UdWdl+aKd9A3T+Tls4jvKs3BJ+DdtlnK7xH4=.jpg',\n",
       " 'id': '0_test890',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nDoes the axial image of the third lumbar vertebra present any visual indicators of heart-related conditions that could be indicative of Ischemic Heart Disease?'},\n",
       "  {'from': 'gpt', 'value': 'No, there are no visual indicators'}],\n",
       " 'option_A': 'A: Yes',\n",
       " 'option_B': ' there are visual indicators',\n",
       " 'option_C': ' B: No',\n",
       " 'option_D': ' there are no visual indicators'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ol_test_data[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "train_path = '/data/aofei/hallucination/CARES/OL3I/training.json'\n",
    "test_path = '/data/aofei/hallucination/CARES/OL3I/test.json'\n",
    "# Save training data\n",
    "print(len(new_ol_train_data))\n",
    "with open(train_path, 'w') as train_file:\n",
    "    json.dump(new_ol_train_data, train_file, indent=2)\n",
    "\n",
    "# Save test data\n",
    "print(len(new_ol_test_data))\n",
    "with open(test_path, 'w') as test_file:\n",
    "    json.dump(new_ol_test_data, test_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
